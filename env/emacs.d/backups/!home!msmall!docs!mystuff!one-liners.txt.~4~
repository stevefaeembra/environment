########################################
#
# FILE SEARCHING SCRIPTS
#
########################################

# Search all files of type *.pl for search string @ed.ac.uk, use '-l' 
# if you only want the name of the file and not the text line.
# On linux you can use grep -r <text> * for every file to be checked.
find . -name '*.pl' -exec grep "@ed.ac.uk" '{}' \; -print 

# Delete files in ~/GGtemp that where modified within the last 100 days.
# Change -100 to +100 for files modified over 100 days ago.
find ~/GGtemp/ -mtime -100 -type f -exec rm -rf {} \;

# Find & replace text in file(s) using perl.
find . -name '*.xml' -exec perl -pi -w -e 's/ows://g' {} \;

# Set the permissions for all sub-directories to rwx.
find  -type d -exec chmod 777 '{}' \;

# Change the permissions of only files in the current directory, if you want to change
# files in sub-directories, remove the maxdepth option.
find -maxdepth 1 -type f -exec chmod 664 {} \;

# Find files larger than $2 in dir $1 and below.
# The awk command takes long listing output and only outputs the filename and size.
find $1 -type f -size +"$2"M -exec ls -lh {} \; #| awk '{ print $9 ": " $5 }'

# Get totoal size of all directories under current directory.
for f in *; do du -sh $f; done

# Find *.svg files in subdirs, ignoring directory target.
find . -path '*target*' -prune -o -name "*.svg" -print

# Find *.svg files in subdirs ignoring directories target and mfbase.
find . -path '*target*' -prune -o -path '*mfbase*' -prune -o -name "*.svg" -print

# Find libxml, omitting any errors such as Permission denied
find / 2>/dev/null -name *libxml* -print


#Solaris grep excluding directory.
/usr/sfw/bin/ggrep corbett -r --exclude=\*data .
# Linux grep excluding directory.
grep -r --exclude-dir="dev" class *

# On Solaris find files above 1Gb.
find . -type f -size +1099678452c -exec ls -lh {} \;

# Find lines matching time pattern in access file and output to *.log file.
ggrep '23:[0-9]\{2\}:' access_log.2012-02-06 > 23-43.log

# Emulate grep with sed (p at the end is what makes this work).
cat test.txt | sed -n '/Hello/p'
cat test.txt | sed '/Hello/!d' # Be carefult to ensure you omit -n
# Emulate grep -v with sed (!p at the end is what makes this work).
cat test.txt | sed -n '/Hello/!p'
cat test.txt | sed '/Hello/d' # Be carefult to ensure you omit -n

# Find files modified between 2 dates, print out the date and filename (Solaris).
find . -type f -exec ls -E {} \; | awk '{print $6,$NF}' | nawk '{gsub(/-/,"",$1);print}' | awk '$1>= 20110217 && $1<= 20110331 {print $1 $2}'
# Linux
find . -type f -exec ls -l --time-style=full-iso {} \; | awk '{print $6,$NF}' | awk '{gsub(/-/,"",$1);print}' | awk '$1>= 20120119 && $1<= 20120121 {print $1 $2}'

# Find files between 2 dates and copy them to another directory.
find . -type f -exec ls -E {} \; | awk '{print $6,$NF}' | nawk '{gsub(/-/,"",$1);print}' | awk '$1>= 20110217 && $1<= 20110331 {print $2}' | xargs -I {} cp '{}' tmp/

# find files between 2 dates and zip them.
find . -name 'access*' -exec ls -E {} \; | awk '{print $6,$NF}' | nawk '{gsub(/-/,"",$1);print}' | awk '$1>= 20120214 && $1<= 20120302 {print $2}' | sort | xargs -I {} gzip '{}'

# Find whole word only.
grep -w <word> <file>

########################################


# Format JSON
cat <file> | python -mjson.tool > <output file>

# Remove blank lines from file (NOTE: Make sure file is not dos file first).
fromdos -d <filename>
sed -i '/^$/d' <filename>
# Delete lines matching regex.
sed -i~ '/<regex>/d' <filename>

# Edit file inline, wrap matching text with other text e.g. /text/read & line 1/g changes text to read text line 1.
sed -i~ "s#text#begin & end#g" <filename>
# A proper example, match date (formatted '2012-01-24 12:41:00') wrap with {ts } to become { ts '2012-01-24 12:41:00' }
sed -i~ "s#'[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\} [0-9]\{2\}:[0-9]\{2\}:[0-9]\{2\}'#{ts &}#g" authorisation_data.sql

# Edit all files beginning with test, replace JAVA_HOME_1_5 with JAVA_HOME_1_6.
for f in `ls test*`; do echo $f; sed 's/JAVA_HOME_1_5/JAVA_HOME_1_6/g' $f > $f.new; mv $f.new $f; done

# Find all files of type java and convert tabs to spaces.
find . -name *.java | while read f; do expand -t2 $f > $f.new; mv $f.new $f; done

# Convert each filename in directory from uppercase to lowercase.
for f in *; do echo $f | tr [:lower:] [:upper:]; done
perl -e 'opendir(DIR,"./temp"); foreach $fn (readdir (DIR)) { rename "./temp/$fn", lc("./temp/$fn"); }; closedir(DIR)'

# Remove from start of line any digits followed by any number of whitespace.
perl -pi~ -e 's/^\d*\s*//g' popups.html

# Replace all matches to '>    </rim:LocalizedString>' or '></rim:LocalizedString>' with '/>'.
# The -0666 is an octal record separator (must be above 256 so it doesn't match any of the
# ascii character set). The hashes are used to delineate the regexp so it doesn't get confusing
# with all the forward slashes '/'.  The 'msg' at the end is for multi-lined matching. the regexp
# iself states substitute any occurrence of a '>' followed by zero or more spaces followed by zero
# or more newlines, followed by zero or more spaces, followed by </rim:LocalizedString> and
# replace it with '/>'.
perl -0666 -pi~ -e "s#>\s*\n*\s*</rim:LocalizedString>#/>#msg" ./test.xml

# Replace all whitespace between > and any alphanumeric character or a - symbol.
# (?=...) means match everything after = symbol but do not include it in the replace.
# So s/abc(?=def)//g will remove all occurrences of abc followed immediately by def,
# but not remove def.
perl -0666 -pi~ -e "s#>\s*(?=[a-zA-Z0-9-])#>#msg" ./test.xml

# Remove DOS newlines (^M) from end of all lines in file.
perl -pi~ -e 's/\r//g' filename

# Replace everything after pattern match using perl in file.
perl -pi~ -e '/^a9_contact_person\s*=\s*(.*)/g; s/$1/m\.small@ed\.ac\.uk/g' *




# Get all files under directory '1.0.0' directory structure  will be schemas/ows/1.0.0/<files>
# You can specify only files of type *.gif by adding '-A *.gif' before url.
# You can get rid of dir structure by adding --cut-dirs=1 would save ows/1.0.0/<files>
wget -r --no-parent --nH http://schemas.cubewerx.com/schemas/ows/1.0.0/ 

# Send GET request to url to WFS and output response to file big.gml
wget 'http://nlwis-snite1.agr.gc.ca/cgi-bin/ogc/eco_wfs_e?service=wfs&version=1.0.0&request=GetFeature&TypeName=ecozones' -Obig.gml

# Post an xml file to the URL and output to stdout NOTE: if server is strict the --header must be
# included, otherwise it can be ommitted.
wget --header "Content-Type: text/xml" --post-file=foo.xml URL -O -

# Post a form to a service, -F means form key/value pair.  Post multiple key/value pairs to url.
curl -F "document=@test.txt" -F "type=plain" -F "gazetteer=geonames" -F "outputFormat=basic" http://unlock.edina.ac.uk/parser/service-results/

curl -d "product=Geology625k&srs=EPSG%3A27700&request=PrintMap&format=application%2Fpdf&width=777&height=451&bbox=-417200.0%2C204800.0%2C1117200.0%2C1095200.0&template=EDINA_bgs_A4Landscape&paper=A4*%40300dpi&customData=Title%3A%3BUsersname%3Aanonymous+anonymous%0AAnonymousEdina&layers=46002%2C46004%2C46005%2C46007%2C46014&styles=default&scale=5600000&type=WMS&swd=Geology625k_cuts_print.swd&scalebar=true&annotations=%7B%22type%22%3A%22FeatureCollection%22%2C%22features%22%3A%5B%7B%22type%22%3A%22Feature%22%2C%22id%22%3A%22OpenLayers.Feature.Vector_663%22%2C%22properties%22%3A%7B%22internal%22%3Afalse%2C%22marker%22%3Atrue%2C%22fcode%22%3A663%2C%22pointRadius%22%3A12%2C%22fontSize%22%3A%2224px%22%2C%22fontFamily%22%3A%22Arial%22%2C%22fontColor%22%3A%22%23000000%22%2C%22fontWeight%22%3A%22bold%22%2C%22textBold%22%3Atrue%2C%22textItalics%22%3Afalse%2C%22textUnderlined%22%3Afalse%2C%22labelHaloColor%22%3A%22%23FFFFFF%22%2C%22labelHaloWidth%22%3A4%2C%22strokeColor%22%3A%22%23000000%22%2C%22strokeOpacity%22%3A1%2C%22strokeStyle%22%3A%22solid%22%2C%22strokeWidth%22%3A2%2C%22strokeLinecap%22%3A%22round%22%2C%22labelAlign%22%3A%22lb%22%2C%22alignment%22%3A8%2C%22labelXOffset%22%3A14%2C%22labelYOffset%22%3A14%2C%22symbol%22%3A%22markers.medium.balloon%22%2C%22fillColor%22%3A%22%23FF6666%22%2C%22fillOpacity%22%3A1%7D%2C%22geometry%22%3A%7B%22type%22%3A%22Point%22%2C%22coordinates%22%3A%5B329256.662%2C571965.538%5D%7D%7D%5D%2C%22crs%22%3A%7B%22type%22%3A%22name%22%2C%22properties%22%3A%7B%22name%22%3A%22EPSG%3A27700%22%7D%7D%7D" http://dee-at.edina.ac.uk:6992/clive/clive

# HTTP GET Request using curl.
curl -G -d "source=/home/digimap/digimap_download_area/edi:2fmt1uvmdxg47w6b/1924910612/data&destination=/home/digimap/digimap_download_area/edi:2fmt1uvmdxg47w6b/1924910612/Data.zip&type=zip" http://alder.edina.ac.uk:11054/compression/compress

# Count number of files ending with '.tgz'.
ls -l *.tgz | wc -l




# Encrypt file using private key.
gpg -e -r <name> <file>

# Decrypt gpg file (must be in this order).
gpg -o filename.txt -d filename.gpg

# Or, if you just want some line(s) of the file displayed to the screen.
gpg -d filename.gpg | grep 'word from file'




# If uname -a fails to give enough info on what distro is being used.
dmesg | head -10




# What version of ubuntu am I running.
lsb_release -a

# Get whether machine is 32-bit, 64-bit or both (For Sun machines only).
isainfo -v




# Backup binary differences of directory to remote machine.
rdiff-backup -v6 --exclude-symbolic-links /home/msmall msmall@dlib-mumra2.ucs.ed.ac.uk::/home/msmall/backups 
# Restore binary differences, this is the file 3 days ago, you can use 'now' to get the latest.
rdiff-backup -r 3 msmall@dlib-mumra.ucs.ed.ac.uk::/home/msmall/backups/home/docs/mystuff/one-liners.txt one-liners.txt 


# Use HtmlTidy to format file, using config file to set options (see http://tidy.sourceforge.net/docs/Overview.html
# for possible options).
tidy -config ~/docs/mystuff/tidy.conf --output-file output.xml input.xml

# Use xmllint to validate xml/html files.
xmllint --valid --noout --schema <schemafile> <file-to-validate>

# Go to previous dir.
cd -




########################################
#
# SED SCRIPTS
#
########################################

# Remove lines with <MATCH> in it from file.
sed -i '/<MATCH>/d' tmp.txt
   
# Remove all empty lines from file (even those with spaces) and output to new file.
sed '/^ *$/d' tmp.txt > tmp2.txt
   
# for each *.owl file in this directory, remove everything between the open/close parenthesis (inclusive).
for f in *.owl; do mv $f `echo $f | sed -e 's/(.*)//g'`; done

# Remove first 2 characters and everything after the last period from string (used for filenames).
echo $1 | sed -e 's/^..\(.*\).shp/\1/g';

# Replace www.edina with edina globally in all html files in current directory.
for f in *.html; do sed -i~ -e 's/www\.edina/edina/g' $f; done



# Mysql update single column.
update record_source set spider_technique_id = 1 where record_source_id = 45;

# View ports being listened on.
netstat --inet -lp -n

# Convert any image to the necessary size, then convert the result to a favicon.ico
anytopnm < myfile.gif | pnmscale -xysize 16 16 | ppmtowinicon > favicon.ico

# List all files ending with '_fgdc.xml' last modified on Nov 2 or Nov 20-29, 
# cut the filename and copy result to Isite GoGeo directory.
cp `ls -rtl *_fgdc.xml | grep "Nov 2" | cut -d ' ' -f 20 ` ~/Isite2.07i/GoGeo

# Shutdown tomcat(s) belonging to <USER>
../bin/shutdown.sh && sleep 2 && kill `ps -fu <USER> |grep java |grep -v grep |cut -d\ -f6` && sleep 2 && ps -fu <USER> |grep java |grep -v grep

# Completely remove package from system.
apt-get --purge remove <packagename>

# Include each referenced xml include file in Basic-pkg.xml into a new file.
java -classpath ../xincluder/xincluder.jar com.elharo.xml.xinclude.SAXXIncluder ./Basic-pkg.xml > output.xml

# Utilize GNU make's ability to use more than one processor.
make -j6




########################################
#
# FILE INTEGRITY SCRIPTS
#
########################################

# Check file integrity using sha1 algorithm and output to file.
sha1sum <filename> > <filename>.sha1

# Check file integrity using sha1 alorithm against value in file.
# NOTE: file being checked and file with value must be the same.
sha1sum -c <filename>.sha1

# Check file integrity using md5 alorithm.
md5sum <filename>
digest -v -a md5 <filename>




# Get environment variables for process on Solaris.
pargs -e <pid>

# Get evironment variables for process on Linux.
# This is a function in .bash_functions I wrote that
# executes the command 'cat /proc/<pid>/environ'
psenv <pid>

# Switch subversion to use a different server.
svn switch --relocate http://geodev.edina.ac.uk http://pentlands2.ed.ac.uk:16020 --username msmall1

# Add a user that cannot log in from graphical login screen (system user), do as root.
adduser --system --shell /bin/bash <username>
passwd <username>


########################################
#
# IPTABLES SCRIPTS
#
########################################

# Get a verbose listing of entries in iptables using ip address instead
# of domain names.
iptables -L -vn

# Remove the 4th entry from the INPUT chain in iptables (counting starts from 1).
iptables -D INPUT 4

# Add a static ip entry to iptables.
iptables -A INPUT -i eth0 -s x.x.x.x -j ACCEPT

# Add a subnet entry to iptables.
iptables -A INPUT -i eth0 -s x.x.x.0/24 -j ACCEPT

# Accept tcp (ssh) traffic from ip.
iptables -A INPUT -p tcp -s x.x.x.x --dport 22 -m state --state NEW -j ACCEPT




# Reboot system if all else fails (including Ctrl-Alt-Delete)
# s = sync, u = unmount, b = reboot.
Alt-SysRq-sub

# Manually mount orthus.
mount -t cifs //orthus.ucs.ed.ac.uk/datalib /home/murray/orthus -o user=ed\\mking4,rw


# Setup dual monitors using xrandr.
# Enable connections using their preferred mode.
xrandr --auto
# Set the outputs (monitors), --right-of states monitor DVI-I_1/digital should
# be on the right of DVI-I_2/digital.
xrandr --output DVI-I_1/digital --right-of DVI-I_2/digital

# Swap from dual monitor to single monitor mode.
# Set DVI-I_2/digital to be the single monitor, and remove DVI-I_1/digital.
xrandr --output DVI-I_1/digital --off


########################################
#
# FILE RENAMING SCRIPTS
#
########################################

# Get the filename only, i.e.strip off the path, useful for removing prefix.
path=/home/msmall/textfile.txt; echo ${path##*/}; # output: textfile.txt
path=/home/msmall/textfile.txt; echo ${path#*/};  # output: home/msmall/textfile.txt

# Get the path only, i.e. strip off the filename, useful for removing postfix.
path=/home/msmall/textfile.txt; echo ${path%%/*}; # output: empty, it removes the first '/' onwards.
path=/home/msmall/textfile.txt; echo ${path%/*};  # output: /home/msmall

# For every *.txt file replace any space in the filename with an underscore.
for f in *.txt; do echo $f | sed -e 's/ /_/g'; done

# For each file in dir of type *.owl, edit file inline using perl to replace occurrences
# of the filename with the filename prepended with ao/, create backups just in case.
for f in *.owl; do perl -pi~ -e "s#$f#ao/$f#g" $f; done

# Rename all xml files, remove everything after the hyphen (-) and append '.xml'.
for f in *.xml; do mv $f ${f%-*}.xml; done

# Rename all xml files, remove everything after the period (.) and append '-tidy.xml'.
# may need to put a * in ${f%.*}
for f in *.xml; do mv $f ${f%.}-tidy.xml; done

# Rename all *.m4a files, insert ' - ' after the first 2 digits of the filename.
for f in *.m4a; do mv "$f" "`echo $f | sed -e "s/\([0-9][0-9]\) /\1 - /"`"; done

# Rename all avi files, remove first 4 characters from the filename.
for f in *.avi; do mv "$f" "${f:4}"; done

# Rename all avi files, remove first 12 characters and replace anything after ' [' with
# '.avi'.
for f in *.avi; do o="${f:12}"; out=$(echo $o | sed -e 's/\ \[.*/\.avi/'); mv $f "$out"; done 

########################################



# Get the size of each sub-directory of current directory.
for i in */; do du -sH $i; done

# Search through every jar file in dir and find which has <package>
for f in *.jar; do echo $f; unzip -l $f | grep '<package>'; done



########################################
#
# FILE CONVERTING SCRIPTS
#
########################################

# Convert all shapefiles in directory to UTF-8, pass filename to function and output to *.sql file 
# of same name minus prefix & postfix.
for f in *.shp ; do shp2pgsql -g the_geom -W UTF-8 -I $f `foo $f` > `foo $f`.sql;done

# To convert a single shapefile to a sql file.
shp2pgsql -g the_geom -W UTF-8 -I szUN_SURVEY_region.shp SURVEY > ../test.sql

# Go into each directory and run command.
dir=$PWD; for f in `ls`; do echo $f; cd $dir/$f; svn --non-interactive update; done

########################################



# Display the top 10 CPU users on the Linux system (use 'head -10' for top 
# 10 else replace with less for all processes in order).
ps -eo pcpu,pid,user,args | sort -k 1 -r | head -10
# FOR solaris only, get the environment of specified process.
/usr/ucb/ps auxwwee | grep 27136 | grep -v grep


# DCOP, send message to running application from the command-line.
# dcop <name of app> <interface of app> <action>
dcop kontact kontact-mainwindow#1 restore

# ssh port forwarding.
ssh -L 16020:devel.edina.ac.uk:16020 msmall@dlib-mumra.ucs.ed.ac.uk
# all traffic to port 1234 on client host will be forwarded to port 23 on localhost.
ssh2 -L 1234:localhost:23 username@host

# Use svn from home.
# 1) Use mumra to connect to the devel machine.
ssh -L 16020:devel.edina.ac.uk:16020 msmall@dlib-mumra.ucs.ed.ac.uk
# 2) Run svn commands from home machine.
svn ls http://localhost:16020/svn/geo-dev/compass


# Cat multiple media files together.
mencoder -forceidx -oac copy -ovc copy file1 file2 file3 â€¦ -o final_movie.mpg


# Grep for whole word only, word can occur anywhere in line.
egrep '[^a-z]Conductivity' results.txt


# Remove text from beginning and end of each line in file and output to a new file.
# Removes 1, 2 & 4 columns from source.txt and prints the output to file destination.txt
awk '{ $1 = ""; $2 = ""; $4 = ""; print }' source.txt > destination.txt


# Diff & Patch
#Create a diff for a single file.
diff -u <dir>/orig.txt <dir>/new.txt > orig.patch
# Patch single file.
patch <dir>/orig.txt < orig.patch
 

# Kill processes by name (Solaris).
kill `ps auxww | grep netscape | egrep -v grep | awk '{print $2}'`
# Kill all process that start with '/bin/sh -' (sometimes you must kill with a vengence).
kill -9 `mps | grep '/bin/sh -' | grep -v ggrep | awk '{print $2;}'`  
# Kill all httpd processes for user.
ps -fu tilelive | grep httpd | grep -v grep | awk '{print $2}' | xargs kill -9

# Execute a program periodically, showing output on screen.
# Execute iptables -nvL every 1 second(s).
watch -n 1 iptables -nvL

# Grep
# Some newer grep functionality.
# Only display matching filename and the matching text, not the entire line.
grep -o <pattern> <files>


# Get the backup from one day previous (not the latest), mumra can be used because it is in
# the config file for ssh and there is no need for an absolute path, it takes the CWD as the
# users home directory.
rdiff-backup -r 1D mumra::backups/home/dev/workspace/csw-broker/src/test/resources resources


# Set debian to log boot messages.
add BOOTLOGD_ENABLE=Yes to /etc/default/bootlogd

# Extend Logical Volume.
see man page examples for lvextend.
see man page for resize2fs.


# Purge all removed packages that have config files left over (must be run as root).
dpkg -l | grep ^rc | cut -d ' ' -f3 | xargs dpkg -P

# live-helper create usb startup 
lh_config -b usb-hdd --debian-installer netinst -d sid --hooks virtualbox-ose.sh --hooks modules --hostname void --categories main contrib non-free -k 2.6.29-1-686 -m http://ftp.uk.debian.org/debian


# On sun system (and debian if no package is available).
# Install new module so it is accessible in @INC modules array.
perl -MCPAN 'install Name::Of::The::Module'


# Maven - Package/Install/Deploy a file without running tests.
mvn -Dmaven.test.skip=true package/install/deploy

# Maven - Install a file into your local repository.
mvn install:install-file -Dfile=compass-recommendations-1.4.1.jar -DgroupId=compass.recommendations -DartifactId=compass-recommendations -Dversion=1.4.1 -Dpackaging=jar -DgeneratePom=true

# Maven - Deploy a file to EDINA's repository.
# This will ask you for a password a number of times, the password is that of the subvrsn user account.
mvn deploy:deploy-file -Durl=scp://devel.edina.ac.uk/home/subvrsn/public_docs/maven-repository -DrepositoryId=edina-repository -Dpackaging=jar -Dversion=1.3 -DgroupId=compass.recommendations -DartifactId=compass-recommendations -Dfile=compass-recommendations-1.3.jar


# Match string up to a character (non inclusive) using egrep.
egrep -o "www.deegree.org_app-[^<]*" <filename>

# SOLARIS.
# Find files created after some time, solaris only lets you check for days 
# using atime, ctime, mtime.  Create a file specifying it's creation time,
# Then check if an file in the search directory is newer than that file.
# Create file tmp.txt with timestamp of July 28 10:00am
touch -mt 07281000 tmp.txt
# Find files newer than tmp.txt
find . -newer tmp.txt -local -print

# Connect to remove postgres.
# e.g. psql -U digimap -h awe.edina.ac.uk -p 6700 -d live_digimap
psql -U <username> -h <host> -p <port> -d <dbname>


# Validate xml using xerces.
java -Xss2m -Xmx512m -cp /usr/share/doc/libxerces2-java-doc/examples/xercesSamples.jar:/usr/share/java/xercesImpl.jar:/usr/share/java/xmlParserAPIs.jar sax.Counter -n -np -v -s /home/msmall/docs/projects/motiive/stfc/features/latest/ebFTC_GML.v2.0.xml


# Compile Dynamic Shared Object (DSO) module for apache e.g. mod_proxy.
apxs -i -a -c mod_proxy.c

# tarzip all dirs/files in login-pages excluding any hidden.
tar zcvf login-pages.tgz login-pages --exclude '.*'

# Securely sync a directory between login-pages on localhost and mumra.
rsync -avuz --cvs-exclude --exclude '.*' -e ssh login-pages mumra:

# Securely copy a file/directory to host:dir with resume capability
# e.g. If copy only partially copies, next time it will copy from
# where it finished.
sync -P -essh <file> <host>:<dir>

# Network unreachable in Java only.
# The problem is that there is a bug in java regarding ipv6.
# To discover if this is the problem, run:
sysctl net.ipv6.bindv6only
# If this value is 1, you need to disable the setting:
sysctl net.ipv6.bindv6only=0
# To permanently change this, edit /etc/sysctl.d/bindv6only.conf and set value to zero.



# Stow usage.
stow -d <dir above location of links> <dir of app>
# This creates links to httpd-2.1.12/bin /man etc into /home/user/local 
stow -d /home/user/local/apps httpd-2.1.12
# If in directory local.
stow -t . <app>

# Query DNS server, get it's IP among other things.
nslookup ness.edina.ac.uk


# SOLARIS - Discover what application is using a particular port.
# As digilive user.
sudo lsof | grep <port number>
lsof -i TCP : <port number>
# As whatever user port is being used by.
/usr/ucb/ps auxwwee | grep <port number> | grep -v grep


# Transform using XSL stylesheet.
xalan -xsl <stylesheet> -in <input> -out <output>


# Count the number of occurences a tilde occurs in a file.
perl -lne '$c++ while /~/g; END { print $c; }' test.txt

# Connect to remote Windows machine using user account msmall1,
# set screen size and host to connect to.
rdesktop -u ed\\msmall1 -g 1024x768 lui.edina.ac.uk

# Command-line options for module-assistant.
m-a a-i <module name> e.g. m-a a-i virtualbox-ose-module


# Get the process id of each process with config.file in the line, use the id as
# the parameter to the showps function (this outputs the processes environment.
mps | grep config.file | grep -v grep | awk '{print $2}' | while read i; do showps "$i"; echo ' '; done

# The same thing but grep for phrase from processes environment, limits output.
mps | grep config.file | grep -v grep | awk '{print $2}' | while read i; do showps "$i" | grep cosmo-free; done

# Show modules loaded.
apache2 -t -D DUMP_MODULES


# Setup some environment stuff only if logged in from particular machine i.e. dlib-hibernia.
ip=`echo $SSH_CLIENT | cut -d ' ' -f1`
if [ $ip == '129.215.169.182' ]; then
  source ~/.bashrc_mark-small
fi

# sed script to wrap csv fields in file with double quotes and output to file.
sed -re 's/([0-9]+)/"\1"/g' marine_scales_mark.csv > test.csv

# Get all directories in current directory.
for f in */; do echo $f; done

# Get start/stop dates for VPN certificates in current directory.
for f in `ls *.crt`; do echo $f; openssl x509 -noout -in $f -dates; echo ''; done

# Discover if your on a machine or container in Solaris (global if machine, container name(s) if not).
/usr/sbin/zoneadm list

# Configure authorized_keys
# No need for authorized_keys2, all in there should be copied to authorized_keys.
# Ensure .ssh directory permissions are: 700.
# Ensure authorize_keys file permissions are: 600


# Get apache logs for datetime to another file.
cat access_log.2012-04-03 | sed -n '/03\/Apr\/2012:10/p' > <filename>
# Get filename matching search term into filename.
grep -l <search term> * | uniq > <filename>
# list the files in date order from file.
for f in `cat <filename>`; do ls -lhrt $f; done

# Reduce the size of all PNG images under current directory.
find . -name \*.png -exec pngcrush -rem alla -reduce -brute '{}' '{}.crushed' \; -exec mv '{}.crushed' '{}' \;


# Discover what perl modules are installed.
instmodsh

# Search with less for word 'Gwyn' only.
/\<Gwyn\>

# find 403 errors in apache log file.
grep 'HTTP\/1\.1" 403' access_log.2012-08*

# Backup schema
pg_dump --host awe.edina.ac.uk --port 6700 --username digimap --no-password  --format plain --inserts --verbose --file logs-backup.backup --schema logs mark_tmp
# Select all table names in schema.
select distinct tablename from pg_tables where schemaname = 'logs';

# Use sed to get logs between time range in apache log file.
sed -n '\|24/Oct/2012:09:14|,\|24/Oct/2012:09:24|p' access_log.2012-10-24 > test.log

# Remove all but the current linux kernel, also removes headers and kbuild(s).
apt-get remove $(dpkg -l|egrep '^ii  linux-(im|he|kb)'|awk '{print $2}'|grep -v `uname -r`)
